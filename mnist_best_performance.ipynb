{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "jXgBeMJDEy8w",
    "outputId": "c3d4c9da-bbce-4468-d389-dd9e28e32ad5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# https://keras.io/\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vl6O6xXhGyaS"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Add\n",
    "from keras.layers import Convolution2D, MaxPooling2D,AveragePooling2D\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "PfTPYdd_G4od",
    "outputId": "234d16a9-71fc-4ea8-d9bb-12f553404a9e"
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "colab_type": "code",
    "id": "7G8aEx7IG_o2",
    "outputId": "6a598a04-86b5-45d7-dc71-2744eede9555"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e38c54b278>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e3883c6c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print (X_train.shape)\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "thGaPs5bHIBt"
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GB_c2v6jHNc3"
   },
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4B7JuYKsHSTw"
   },
   "outputs": [],
   "source": [
    "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 199
    },
    "colab_type": "code",
    "id": "sJTw27rjHZeM",
    "outputId": "383ce549-2b43-4437-8362-30db4981f31b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eUz7vyqtHey_"
   },
   "outputs": [],
   "source": [
    "from keras.layers import AveragePooling2D\n",
    "from keras.layers import SeparableConv2D\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(Convolution2D(32, (3, 3), activation='relu', input_shape=(28,28,1)))\n",
    "model.add(SeparableConv2D(64, (3, 3), activation='relu'))\n",
    "model.add(SeparableConv2D(64, (3, 3), activation='relu'))\n",
    "model.add(SeparableConv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Convolution2D(32, 1, activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(SeparableConv2D(32, (3, 3), activation='relu'))\n",
    "model.add(SeparableConv2D(32, (3, 3), activation='relu'))\n",
    "model.add(SeparableConv2D(32, (3, 3)))\n",
    "model.add(SeparableConv2D(32, (3, 3)))\n",
    "model.add(AveragePooling2D())\n",
    "model.add(Convolution2D(10, 1))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 655
    },
    "colab_type": "code",
    "id": "FvKPQw--IaMi",
    "outputId": "124dbaaf-5f97-47a4-e717-db5290b0389b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "separable_conv2d_1 (Separabl (None, 24, 24, 64)        2400      \n",
      "_________________________________________________________________\n",
      "separable_conv2d_2 (Separabl (None, 22, 22, 64)        4736      \n",
      "_________________________________________________________________\n",
      "separable_conv2d_3 (Separabl (None, 20, 20, 64)        4736      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 20, 20, 32)        2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_4 (Separabl (None, 8, 8, 32)          1344      \n",
      "_________________________________________________________________\n",
      "separable_conv2d_5 (Separabl (None, 6, 6, 32)          1344      \n",
      "_________________________________________________________________\n",
      "separable_conv2d_6 (Separabl (None, 4, 4, 32)          1344      \n",
      "_________________________________________________________________\n",
      "separable_conv2d_7 (Separabl (None, 2, 2, 32)          1344      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 1, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 1, 1, 10)          330       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 19,978\n",
      "Trainable params: 19,978\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vXvJ7nB3JwB1"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 4700
    },
    "colab_type": "code",
    "id": "Do4Ju-AAJ2vR",
    "outputId": "de25ac26-ad2a-4987-b1b4-8806a5159d90"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/125\n",
      "60000/60000 [==============================] - 25s 414us/step - loss: 2.3019 - acc: 0.1086\n",
      "Epoch 2/125\n",
      "60000/60000 [==============================] - 17s 279us/step - loss: 2.3012 - acc: 0.1124\n",
      "Epoch 3/125\n",
      "60000/60000 [==============================] - 17s 279us/step - loss: 2.3012 - acc: 0.1124\n",
      "Epoch 4/125\n",
      "60000/60000 [==============================] - 17s 283us/step - loss: 2.3012 - acc: 0.1124\n",
      "Epoch 5/125\n",
      "60000/60000 [==============================] - 17s 289us/step - loss: 2.2976 - acc: 0.1125\n",
      "Epoch 6/125\n",
      "60000/60000 [==============================] - 17s 292us/step - loss: 1.5210 - acc: 0.5068\n",
      "Epoch 7/125\n",
      "60000/60000 [==============================] - 18s 294us/step - loss: 0.7056 - acc: 0.7832\n",
      "Epoch 8/125\n",
      "60000/60000 [==============================] - 18s 297us/step - loss: 0.4216 - acc: 0.8713\n",
      "Epoch 9/125\n",
      "60000/60000 [==============================] - 18s 293us/step - loss: 0.3190 - acc: 0.9028\n",
      "Epoch 10/125\n",
      "60000/60000 [==============================] - 18s 296us/step - loss: 0.2583 - acc: 0.9197\n",
      "Epoch 11/125\n",
      "60000/60000 [==============================] - 18s 296us/step - loss: 0.2209 - acc: 0.9310\n",
      "Epoch 12/125\n",
      "60000/60000 [==============================] - 18s 294us/step - loss: 0.1944 - acc: 0.9396\n",
      "Epoch 13/125\n",
      "60000/60000 [==============================] - 18s 298us/step - loss: 0.1767 - acc: 0.9452\n",
      "Epoch 14/125\n",
      "60000/60000 [==============================] - 18s 299us/step - loss: 0.1604 - acc: 0.9507\n",
      "Epoch 15/125\n",
      "60000/60000 [==============================] - 18s 297us/step - loss: 0.1495 - acc: 0.9536\n",
      "Epoch 16/125\n",
      "60000/60000 [==============================] - 18s 294us/step - loss: 0.1379 - acc: 0.9568\n",
      "Epoch 17/125\n",
      "60000/60000 [==============================] - 18s 295us/step - loss: 0.1289 - acc: 0.9602\n",
      "Epoch 18/125\n",
      "60000/60000 [==============================] - 17s 291us/step - loss: 0.1222 - acc: 0.9620\n",
      "Epoch 19/125\n",
      "60000/60000 [==============================] - 18s 294us/step - loss: 0.1155 - acc: 0.9642\n",
      "Epoch 20/125\n",
      "60000/60000 [==============================] - 18s 295us/step - loss: 0.1095 - acc: 0.9660\n",
      "Epoch 21/125\n",
      "60000/60000 [==============================] - 18s 297us/step - loss: 0.1035 - acc: 0.9679\n",
      "Epoch 22/125\n",
      "60000/60000 [==============================] - 18s 298us/step - loss: 0.0971 - acc: 0.9703\n",
      "Epoch 23/125\n",
      "60000/60000 [==============================] - 18s 296us/step - loss: 0.0948 - acc: 0.9703\n",
      "Epoch 24/125\n",
      "60000/60000 [==============================] - 18s 299us/step - loss: 0.0911 - acc: 0.9716\n",
      "Epoch 25/125\n",
      "60000/60000 [==============================] - 18s 298us/step - loss: 0.0869 - acc: 0.9729\n",
      "Epoch 26/125\n",
      "60000/60000 [==============================] - 18s 300us/step - loss: 0.0831 - acc: 0.9748\n",
      "Epoch 27/125\n",
      "60000/60000 [==============================] - 18s 300us/step - loss: 0.0823 - acc: 0.9748\n",
      "Epoch 28/125\n",
      "60000/60000 [==============================] - 18s 299us/step - loss: 0.0781 - acc: 0.9765\n",
      "Epoch 29/125\n",
      "60000/60000 [==============================] - 18s 297us/step - loss: 0.0757 - acc: 0.9765\n",
      "Epoch 30/125\n",
      "60000/60000 [==============================] - 18s 296us/step - loss: 0.0733 - acc: 0.9770\n",
      "Epoch 31/125\n",
      "60000/60000 [==============================] - 18s 297us/step - loss: 0.0717 - acc: 0.9778\n",
      "Epoch 32/125\n",
      "60000/60000 [==============================] - 18s 297us/step - loss: 0.0706 - acc: 0.9777\n",
      "Epoch 33/125\n",
      "60000/60000 [==============================] - 18s 300us/step - loss: 0.0686 - acc: 0.9791\n",
      "Epoch 34/125\n",
      "60000/60000 [==============================] - 18s 298us/step - loss: 0.0667 - acc: 0.9790\n",
      "Epoch 35/125\n",
      "60000/60000 [==============================] - 18s 299us/step - loss: 0.0654 - acc: 0.9793\n",
      "Epoch 36/125\n",
      "60000/60000 [==============================] - 18s 297us/step - loss: 0.0641 - acc: 0.9795\n",
      "Epoch 37/125\n",
      "60000/60000 [==============================] - 18s 300us/step - loss: 0.0621 - acc: 0.9810\n",
      "Epoch 38/125\n",
      "60000/60000 [==============================] - 18s 299us/step - loss: 0.0603 - acc: 0.9811\n",
      "Epoch 39/125\n",
      "60000/60000 [==============================] - 18s 301us/step - loss: 0.0603 - acc: 0.9808\n",
      "Epoch 40/125\n",
      "60000/60000 [==============================] - 18s 299us/step - loss: 0.0596 - acc: 0.9806\n",
      "Epoch 41/125\n",
      "60000/60000 [==============================] - 18s 301us/step - loss: 0.0573 - acc: 0.9819\n",
      "Epoch 42/125\n",
      "60000/60000 [==============================] - 18s 298us/step - loss: 0.0565 - acc: 0.9822\n",
      "Epoch 43/125\n",
      "60000/60000 [==============================] - 18s 297us/step - loss: 0.0554 - acc: 0.9827\n",
      "Epoch 44/125\n",
      "60000/60000 [==============================] - 18s 299us/step - loss: 0.0563 - acc: 0.9814\n",
      "Epoch 45/125\n",
      "60000/60000 [==============================] - 18s 300us/step - loss: 0.0551 - acc: 0.9824\n",
      "Epoch 46/125\n",
      "60000/60000 [==============================] - 18s 299us/step - loss: 0.0527 - acc: 0.9833\n",
      "Epoch 47/125\n",
      "60000/60000 [==============================] - 18s 295us/step - loss: 0.0520 - acc: 0.9840\n",
      "Epoch 48/125\n",
      "60000/60000 [==============================] - 18s 297us/step - loss: 0.0504 - acc: 0.9839\n",
      "Epoch 49/125\n",
      "60000/60000 [==============================] - 18s 299us/step - loss: 0.0515 - acc: 0.9838\n",
      "Epoch 50/125\n",
      "60000/60000 [==============================] - 18s 298us/step - loss: 0.0512 - acc: 0.9839\n",
      "Epoch 51/125\n",
      "60000/60000 [==============================] - 18s 300us/step - loss: 0.0485 - acc: 0.9843\n",
      "Epoch 52/125\n",
      "60000/60000 [==============================] - 18s 300us/step - loss: 0.0497 - acc: 0.9839\n",
      "Epoch 53/125\n",
      "60000/60000 [==============================] - 18s 298us/step - loss: 0.0481 - acc: 0.9846\n",
      "Epoch 54/125\n",
      "60000/60000 [==============================] - 18s 299us/step - loss: 0.0460 - acc: 0.9851\n",
      "Epoch 55/125\n",
      "60000/60000 [==============================] - 18s 302us/step - loss: 0.0476 - acc: 0.9848\n",
      "Epoch 56/125\n",
      "60000/60000 [==============================] - 18s 298us/step - loss: 0.0469 - acc: 0.9849\n",
      "Epoch 57/125\n",
      "60000/60000 [==============================] - 18s 298us/step - loss: 0.0459 - acc: 0.9852\n",
      "Epoch 58/125\n",
      "60000/60000 [==============================] - 18s 295us/step - loss: 0.0450 - acc: 0.9858\n",
      "Epoch 59/125\n",
      "60000/60000 [==============================] - 18s 301us/step - loss: 0.0445 - acc: 0.9855\n",
      "Epoch 60/125\n",
      "60000/60000 [==============================] - 18s 299us/step - loss: 0.0445 - acc: 0.9856\n",
      "Epoch 61/125\n",
      "60000/60000 [==============================] - 18s 302us/step - loss: 0.0432 - acc: 0.9860\n",
      "Epoch 62/125\n",
      "60000/60000 [==============================] - 18s 301us/step - loss: 0.0429 - acc: 0.9864\n",
      "Epoch 63/125\n",
      "60000/60000 [==============================] - 18s 299us/step - loss: 0.0422 - acc: 0.9862\n",
      "Epoch 64/125\n",
      "60000/60000 [==============================] - 18s 296us/step - loss: 0.0403 - acc: 0.9872\n",
      "Epoch 65/125\n",
      "60000/60000 [==============================] - 18s 301us/step - loss: 0.0425 - acc: 0.9861\n",
      "Epoch 66/125\n",
      "60000/60000 [==============================] - 18s 299us/step - loss: 0.0407 - acc: 0.9866\n",
      "Epoch 67/125\n",
      "60000/60000 [==============================] - 18s 296us/step - loss: 0.0414 - acc: 0.9868\n",
      "Epoch 68/125\n",
      "60000/60000 [==============================] - 18s 300us/step - loss: 0.0397 - acc: 0.9870\n",
      "Epoch 69/125\n",
      "60000/60000 [==============================] - 18s 300us/step - loss: 0.0415 - acc: 0.9864\n",
      "Epoch 70/125\n",
      "60000/60000 [==============================] - 18s 300us/step - loss: 0.0388 - acc: 0.9874\n",
      "Epoch 71/125\n",
      "60000/60000 [==============================] - 18s 301us/step - loss: 0.0382 - acc: 0.9878\n",
      "Epoch 72/125\n",
      "60000/60000 [==============================] - 18s 301us/step - loss: 0.0376 - acc: 0.9878\n",
      "Epoch 73/125\n",
      "60000/60000 [==============================] - 18s 303us/step - loss: 0.0386 - acc: 0.9875\n",
      "Epoch 74/125\n",
      "60000/60000 [==============================] - 18s 301us/step - loss: 0.0381 - acc: 0.9878\n",
      "Epoch 75/125\n",
      "60000/60000 [==============================] - 18s 298us/step - loss: 0.0367 - acc: 0.9884\n",
      "Epoch 76/125\n",
      "60000/60000 [==============================] - 18s 298us/step - loss: 0.0358 - acc: 0.9886\n",
      "Epoch 77/125\n",
      "60000/60000 [==============================] - 18s 300us/step - loss: 0.0370 - acc: 0.9879\n",
      "Epoch 78/125\n",
      "60000/60000 [==============================] - 18s 298us/step - loss: 0.0362 - acc: 0.9882\n",
      "Epoch 79/125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 18s 304us/step - loss: 0.0365 - acc: 0.9881\n",
      "Epoch 80/125\n",
      "60000/60000 [==============================] - 18s 302us/step - loss: 0.0343 - acc: 0.9891\n",
      "Epoch 81/125\n",
      "60000/60000 [==============================] - 18s 300us/step - loss: 0.0351 - acc: 0.9887\n",
      "Epoch 82/125\n",
      "60000/60000 [==============================] - 18s 297us/step - loss: 0.0344 - acc: 0.9888\n",
      "Epoch 83/125\n",
      "60000/60000 [==============================] - 18s 300us/step - loss: 0.0335 - acc: 0.9891\n",
      "Epoch 84/125\n",
      "60000/60000 [==============================] - 18s 299us/step - loss: 0.0335 - acc: 0.9892\n",
      "Epoch 85/125\n",
      "60000/60000 [==============================] - 18s 300us/step - loss: 0.0329 - acc: 0.9895\n",
      "Epoch 86/125\n",
      "60000/60000 [==============================] - 18s 301us/step - loss: 0.0319 - acc: 0.9901\n",
      "Epoch 87/125\n",
      "60000/60000 [==============================] - 18s 301us/step - loss: 0.0320 - acc: 0.9899\n",
      "Epoch 88/125\n",
      "60000/60000 [==============================] - 18s 300us/step - loss: 0.0311 - acc: 0.9898\n",
      "Epoch 89/125\n",
      "60000/60000 [==============================] - 18s 300us/step - loss: 0.0323 - acc: 0.9896\n",
      "Epoch 90/125\n",
      "60000/60000 [==============================] - 18s 299us/step - loss: 0.0336 - acc: 0.9891\n",
      "Epoch 91/125\n",
      "60000/60000 [==============================] - 18s 296us/step - loss: 0.0300 - acc: 0.9906\n",
      "Epoch 92/125\n",
      "60000/60000 [==============================] - 18s 299us/step - loss: 0.0295 - acc: 0.9906\n",
      "Epoch 93/125\n",
      "60000/60000 [==============================] - 18s 300us/step - loss: 0.0299 - acc: 0.9906\n",
      "Epoch 94/125\n",
      "60000/60000 [==============================] - 18s 300us/step - loss: 0.0303 - acc: 0.9902\n",
      "Epoch 95/125\n",
      "60000/60000 [==============================] - 18s 301us/step - loss: 0.0298 - acc: 0.9905\n",
      "Epoch 96/125\n",
      "60000/60000 [==============================] - 18s 302us/step - loss: 0.0289 - acc: 0.9907\n",
      "Epoch 97/125\n",
      "60000/60000 [==============================] - 18s 300us/step - loss: 0.0289 - acc: 0.9906\n",
      "Epoch 98/125\n",
      "60000/60000 [==============================] - 18s 300us/step - loss: 0.0285 - acc: 0.9903\n",
      "Epoch 99/125\n",
      "60000/60000 [==============================] - 18s 299us/step - loss: 0.0269 - acc: 0.9910\n",
      "Epoch 100/125\n",
      "60000/60000 [==============================] - 18s 300us/step - loss: 0.0272 - acc: 0.9913\n",
      "Epoch 101/125\n",
      "60000/60000 [==============================] - 18s 298us/step - loss: 0.0274 - acc: 0.9908\n",
      "Epoch 102/125\n",
      "60000/60000 [==============================] - 18s 301us/step - loss: 0.0281 - acc: 0.9910\n",
      "Epoch 103/125\n",
      "60000/60000 [==============================] - 18s 304us/step - loss: 0.0262 - acc: 0.9916\n",
      "Epoch 104/125\n",
      "60000/60000 [==============================] - 18s 302us/step - loss: 0.0275 - acc: 0.9910\n",
      "Epoch 105/125\n",
      "60000/60000 [==============================] - 18s 302us/step - loss: 0.0264 - acc: 0.9913\n",
      "Epoch 106/125\n",
      "60000/60000 [==============================] - 18s 307us/step - loss: 0.0268 - acc: 0.9915\n",
      "Epoch 107/125\n",
      "60000/60000 [==============================] - 18s 300us/step - loss: 0.0266 - acc: 0.9910\n",
      "Epoch 108/125\n",
      "60000/60000 [==============================] - 18s 305us/step - loss: 0.0258 - acc: 0.9915\n",
      "Epoch 109/125\n",
      "60000/60000 [==============================] - 18s 301us/step - loss: 0.0242 - acc: 0.9925\n",
      "Epoch 110/125\n",
      "60000/60000 [==============================] - 18s 300us/step - loss: 0.0252 - acc: 0.9917\n",
      "Epoch 111/125\n",
      "60000/60000 [==============================] - 18s 297us/step - loss: 0.0246 - acc: 0.9921\n",
      "Epoch 112/125\n",
      "60000/60000 [==============================] - 18s 298us/step - loss: 0.0252 - acc: 0.9922\n",
      "Epoch 113/125\n",
      "60000/60000 [==============================] - 18s 302us/step - loss: 0.0235 - acc: 0.9924\n",
      "Epoch 114/125\n",
      "60000/60000 [==============================] - 18s 298us/step - loss: 0.0239 - acc: 0.9924\n",
      "Epoch 115/125\n",
      "60000/60000 [==============================] - 18s 303us/step - loss: 0.0239 - acc: 0.9924\n",
      "Epoch 116/125\n",
      "60000/60000 [==============================] - 18s 306us/step - loss: 0.0237 - acc: 0.9929\n",
      "Epoch 117/125\n",
      "60000/60000 [==============================] - 18s 301us/step - loss: 0.0245 - acc: 0.9922\n",
      "Epoch 118/125\n",
      "60000/60000 [==============================] - 18s 300us/step - loss: 0.0226 - acc: 0.9930\n",
      "Epoch 119/125\n",
      "60000/60000 [==============================] - 18s 300us/step - loss: 0.0234 - acc: 0.9922\n",
      "Epoch 120/125\n",
      "60000/60000 [==============================] - 18s 298us/step - loss: 0.0264 - acc: 0.9915\n",
      "Epoch 121/125\n",
      "60000/60000 [==============================] - 18s 297us/step - loss: 0.0237 - acc: 0.9923\n",
      "Epoch 122/125\n",
      "60000/60000 [==============================] - 18s 300us/step - loss: 0.0231 - acc: 0.9926\n",
      "Epoch 123/125\n",
      "60000/60000 [==============================] - 18s 301us/step - loss: 0.0221 - acc: 0.9929\n",
      "Epoch 124/125\n",
      "60000/60000 [==============================] - 18s 300us/step - loss: 0.0211 - acc: 0.9935\n",
      "Epoch 125/125\n",
      "60000/60000 [==============================] - 18s 297us/step - loss: 0.0228 - acc: 0.9927\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e38c57b828>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, batch_size=2048, nb_epoch=125, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "mnist_99_31",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
