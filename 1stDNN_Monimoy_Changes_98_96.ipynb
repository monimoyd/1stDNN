{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1stDNN_Monimoy_Changes_98.96.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/monimoyd/1stDNN/blob/master/1stDNN_Monimoy_Changes_98_96.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "_P38hI5pMQn7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FRE_pKeOMloJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Add\n",
        "from keras.layers import Convolution2D, MaxPooling2D,AveragePooling2D\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kDgrP_i6MuAv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X1xcE5w_M0D-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "c85d6b3b-c988-4254-f013-61109d090e6e"
      },
      "cell_type": "code",
      "source": [
        "print (X_train.shape)\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(X_train[0])"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f0b95a7c898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f0b9701e278>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "rnVBLQ0oM3tx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ME3NIhU7M-tt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CL4cTsEDNIVn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3c5829c6-1bef-41d0-f639-9fc1a73c31e2"
      },
      "cell_type": "code",
      "source": [
        "y_train[:10]"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "metadata": {
        "id": "r7Xc2UoLNPUz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2lT78J18NTcH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "a50f054e-1f87-442c-aa88-d15a128b4dc1"
      },
      "cell_type": "code",
      "source": [
        "Y_train[:10]"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "metadata": {
        "id": "1kCv2_NvNYmu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "4e3eb8b8-9214-4cac-ed7b-3eff6c390317"
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Activation\n",
        "from keras.layers import AveragePooling2D\n",
        "model = Sequential()\n",
        "\n",
        "\n",
        "model.add(Convolution2D(64, 3, 3, activation='relu', input_shape=(28,28,1)))\n",
        "model.add(Convolution2D(32, 1, activation='relu'))\n",
        "model.add(Convolution2D(32, 3, 3, activation='relu'))\n",
        "model.add(Convolution2D(16, 1, activation='relu'))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))\n",
        "model.add(Convolution2D(10, 1, activation='relu'))\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu'))\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu'))\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu'))\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu'))\n",
        "model.add(AveragePooling2D())\n",
        "model.add(Convolution2D(10, 1))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\")`\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\")`\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\")`\n",
            "  app.launch_new_instance()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "tq3yh3-yNeXO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 691
        },
        "outputId": "37396468-538b-4398-e2ca-dd1123a98c56"
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_56 (Conv2D)           (None, 26, 26, 64)        640       \n",
            "_________________________________________________________________\n",
            "conv2d_57 (Conv2D)           (None, 26, 26, 32)        2080      \n",
            "_________________________________________________________________\n",
            "conv2d_58 (Conv2D)           (None, 24, 24, 32)        9248      \n",
            "_________________________________________________________________\n",
            "conv2d_59 (Conv2D)           (None, 24, 24, 16)        528       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 12, 12, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_60 (Conv2D)           (None, 10, 10, 16)        2320      \n",
            "_________________________________________________________________\n",
            "conv2d_61 (Conv2D)           (None, 10, 10, 10)        170       \n",
            "_________________________________________________________________\n",
            "conv2d_62 (Conv2D)           (None, 8, 8, 10)          910       \n",
            "_________________________________________________________________\n",
            "conv2d_63 (Conv2D)           (None, 6, 6, 10)          910       \n",
            "_________________________________________________________________\n",
            "conv2d_64 (Conv2D)           (None, 4, 4, 10)          910       \n",
            "_________________________________________________________________\n",
            "conv2d_65 (Conv2D)           (None, 2, 2, 10)          910       \n",
            "_________________________________________________________________\n",
            "average_pooling2d_6 (Average (None, 1, 1, 10)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_66 (Conv2D)           (None, 1, 1, 10)          110       \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 18,736\n",
            "Trainable params: 18,736\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sfd5_mlNNlZ6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fJMBN1neNp1s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5557
        },
        "outputId": "821904c6-f645-49eb-b318-4d92f863ef6f"
      },
      "cell_type": "code",
      "source": [
        "model.fit(X_train, Y_train, batch_size=2048, nb_epoch=150, verbose=1)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/models.py:981: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 2.1219 - acc: 0.2211\n",
            "Epoch 2/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 1.3695 - acc: 0.5120\n",
            "Epoch 3/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.9436 - acc: 0.6881\n",
            "Epoch 4/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.6726 - acc: 0.7918\n",
            "Epoch 5/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.4450 - acc: 0.8670\n",
            "Epoch 6/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.3310 - acc: 0.9020\n",
            "Epoch 7/150\n",
            "60000/60000 [==============================] - 6s 93us/step - loss: 0.2665 - acc: 0.9207\n",
            "Epoch 8/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.2312 - acc: 0.9312\n",
            "Epoch 9/150\n",
            "60000/60000 [==============================] - 6s 93us/step - loss: 0.1946 - acc: 0.9420\n",
            "Epoch 10/150\n",
            "60000/60000 [==============================] - 6s 93us/step - loss: 0.1758 - acc: 0.9477\n",
            "Epoch 11/150\n",
            "60000/60000 [==============================] - 6s 93us/step - loss: 0.1615 - acc: 0.9521\n",
            "Epoch 12/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.1454 - acc: 0.9566\n",
            "Epoch 13/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.1359 - acc: 0.9597\n",
            "Epoch 14/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.1284 - acc: 0.9614\n",
            "Epoch 15/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.1204 - acc: 0.9638\n",
            "Epoch 16/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.1128 - acc: 0.9657\n",
            "Epoch 17/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.1050 - acc: 0.9690\n",
            "Epoch 18/150\n",
            "60000/60000 [==============================] - 6s 93us/step - loss: 0.0999 - acc: 0.9694\n",
            "Epoch 19/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0974 - acc: 0.9701\n",
            "Epoch 20/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0940 - acc: 0.9715\n",
            "Epoch 21/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0879 - acc: 0.9731\n",
            "Epoch 22/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0898 - acc: 0.9730\n",
            "Epoch 23/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0813 - acc: 0.9753\n",
            "Epoch 24/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0802 - acc: 0.9760\n",
            "Epoch 25/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0767 - acc: 0.9765\n",
            "Epoch 26/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0748 - acc: 0.9774\n",
            "Epoch 27/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0713 - acc: 0.9786\n",
            "Epoch 28/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0710 - acc: 0.9777\n",
            "Epoch 29/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0678 - acc: 0.9790\n",
            "Epoch 30/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0674 - acc: 0.9793\n",
            "Epoch 31/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0661 - acc: 0.9804\n",
            "Epoch 32/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0651 - acc: 0.9804\n",
            "Epoch 33/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0661 - acc: 0.9798\n",
            "Epoch 34/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0625 - acc: 0.9810\n",
            "Epoch 35/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0597 - acc: 0.9821\n",
            "Epoch 36/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0621 - acc: 0.9806\n",
            "Epoch 37/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0578 - acc: 0.9820\n",
            "Epoch 38/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0559 - acc: 0.9827\n",
            "Epoch 39/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0547 - acc: 0.9829\n",
            "Epoch 40/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0566 - acc: 0.9825\n",
            "Epoch 41/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0562 - acc: 0.9826\n",
            "Epoch 42/150\n",
            "60000/60000 [==============================] - 6s 93us/step - loss: 0.0575 - acc: 0.9824\n",
            "Epoch 43/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0541 - acc: 0.9833\n",
            "Epoch 44/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0560 - acc: 0.9828\n",
            "Epoch 45/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0517 - acc: 0.9840\n",
            "Epoch 46/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0518 - acc: 0.9840\n",
            "Epoch 47/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0499 - acc: 0.9844\n",
            "Epoch 48/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0500 - acc: 0.9845\n",
            "Epoch 49/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0502 - acc: 0.9846\n",
            "Epoch 50/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0507 - acc: 0.9843\n",
            "Epoch 51/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0461 - acc: 0.9860\n",
            "Epoch 52/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0453 - acc: 0.9863\n",
            "Epoch 53/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0446 - acc: 0.9863\n",
            "Epoch 54/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0503 - acc: 0.9842\n",
            "Epoch 55/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0448 - acc: 0.9857\n",
            "Epoch 56/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0448 - acc: 0.9859\n",
            "Epoch 57/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0430 - acc: 0.9865\n",
            "Epoch 58/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0429 - acc: 0.9869\n",
            "Epoch 59/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0405 - acc: 0.9870\n",
            "Epoch 60/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0408 - acc: 0.9876\n",
            "Epoch 61/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0420 - acc: 0.9869\n",
            "Epoch 62/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0399 - acc: 0.9875\n",
            "Epoch 63/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0385 - acc: 0.9882\n",
            "Epoch 64/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0394 - acc: 0.9875\n",
            "Epoch 65/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0412 - acc: 0.9872\n",
            "Epoch 66/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0387 - acc: 0.9881\n",
            "Epoch 67/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0390 - acc: 0.9877\n",
            "Epoch 68/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0362 - acc: 0.9883\n",
            "Epoch 69/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0412 - acc: 0.9869\n",
            "Epoch 70/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0396 - acc: 0.9874\n",
            "Epoch 71/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0382 - acc: 0.9881\n",
            "Epoch 72/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0357 - acc: 0.9889\n",
            "Epoch 73/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0356 - acc: 0.9890\n",
            "Epoch 74/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0368 - acc: 0.9882\n",
            "Epoch 75/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0347 - acc: 0.9891\n",
            "Epoch 76/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0339 - acc: 0.9895\n",
            "Epoch 77/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0349 - acc: 0.9889\n",
            "Epoch 78/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0324 - acc: 0.9899\n",
            "Epoch 79/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0338 - acc: 0.9896\n",
            "Epoch 80/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0337 - acc: 0.9895\n",
            "Epoch 81/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0345 - acc: 0.9892\n",
            "Epoch 82/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0318 - acc: 0.9901\n",
            "Epoch 83/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0320 - acc: 0.9898\n",
            "Epoch 84/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0310 - acc: 0.9907\n",
            "Epoch 85/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0323 - acc: 0.9898\n",
            "Epoch 86/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0301 - acc: 0.9907\n",
            "Epoch 87/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0291 - acc: 0.9909\n",
            "Epoch 88/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0287 - acc: 0.9912\n",
            "Epoch 89/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0314 - acc: 0.9901\n",
            "Epoch 90/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0318 - acc: 0.9897\n",
            "Epoch 91/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0308 - acc: 0.9906\n",
            "Epoch 92/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0329 - acc: 0.9895\n",
            "Epoch 93/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0302 - acc: 0.9907\n",
            "Epoch 94/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0276 - acc: 0.9916\n",
            "Epoch 95/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0327 - acc: 0.9894\n",
            "Epoch 96/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0269 - acc: 0.9918\n",
            "Epoch 97/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0274 - acc: 0.9917\n",
            "Epoch 98/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0295 - acc: 0.9906\n",
            "Epoch 99/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0276 - acc: 0.9915\n",
            "Epoch 100/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0282 - acc: 0.9912\n",
            "Epoch 101/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0277 - acc: 0.9911\n",
            "Epoch 102/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0286 - acc: 0.9912\n",
            "Epoch 103/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0279 - acc: 0.9910\n",
            "Epoch 104/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0247 - acc: 0.9926\n",
            "Epoch 105/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0245 - acc: 0.9925\n",
            "Epoch 106/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0240 - acc: 0.9929\n",
            "Epoch 107/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0264 - acc: 0.9916\n",
            "Epoch 108/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0267 - acc: 0.9917\n",
            "Epoch 109/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0262 - acc: 0.9915\n",
            "Epoch 110/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0242 - acc: 0.9924\n",
            "Epoch 111/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0249 - acc: 0.9923\n",
            "Epoch 112/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0254 - acc: 0.9917\n",
            "Epoch 113/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0279 - acc: 0.9914\n",
            "Epoch 114/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0239 - acc: 0.9925\n",
            "Epoch 115/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0254 - acc: 0.9919\n",
            "Epoch 116/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0231 - acc: 0.9929\n",
            "Epoch 117/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0232 - acc: 0.9927\n",
            "Epoch 118/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0234 - acc: 0.9924\n",
            "Epoch 119/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0229 - acc: 0.9929\n",
            "Epoch 120/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0227 - acc: 0.9928\n",
            "Epoch 121/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0227 - acc: 0.9929\n",
            "Epoch 122/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0220 - acc: 0.9935\n",
            "Epoch 123/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0253 - acc: 0.9916\n",
            "Epoch 124/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0237 - acc: 0.9926\n",
            "Epoch 125/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0207 - acc: 0.9936\n",
            "Epoch 126/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0215 - acc: 0.9932\n",
            "Epoch 127/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0214 - acc: 0.9930\n",
            "Epoch 128/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0248 - acc: 0.9921\n",
            "Epoch 129/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0205 - acc: 0.9937\n",
            "Epoch 130/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0201 - acc: 0.9936\n",
            "Epoch 131/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0209 - acc: 0.9934\n",
            "Epoch 132/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0192 - acc: 0.9940\n",
            "Epoch 133/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0218 - acc: 0.9934\n",
            "Epoch 134/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0222 - acc: 0.9926\n",
            "Epoch 135/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0201 - acc: 0.9938\n",
            "Epoch 136/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0184 - acc: 0.9941\n",
            "Epoch 137/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0193 - acc: 0.9941\n",
            "Epoch 138/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0195 - acc: 0.9941\n",
            "Epoch 139/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0205 - acc: 0.9933\n",
            "Epoch 140/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0192 - acc: 0.9939\n",
            "Epoch 141/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0189 - acc: 0.9940\n",
            "Epoch 142/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0183 - acc: 0.9946\n",
            "Epoch 143/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0204 - acc: 0.9933\n",
            "Epoch 144/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0230 - acc: 0.9923\n",
            "Epoch 145/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0172 - acc: 0.9947\n",
            "Epoch 146/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0177 - acc: 0.9946\n",
            "Epoch 147/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0171 - acc: 0.9946\n",
            "Epoch 148/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0199 - acc: 0.9935\n",
            "Epoch 149/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0193 - acc: 0.9938\n",
            "Epoch 150/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0188 - acc: 0.9939\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0b97b39518>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "metadata": {
        "id": "nvM-hwREP3Uk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UpW9QYCjQBEQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3e74e3f3-8667-47f1-c1e3-d61996019c15"
      },
      "cell_type": "code",
      "source": [
        "print(score)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.03533929381113994, 0.9896]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZTo3owzcQIwE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f8pvBUe3QOE_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "14d347f9-88ef-4165-be90-3016fa777712"
      },
      "cell_type": "code",
      "source": [
        "print(y_pred[:9])\n",
        "print(y_test[:9])"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[4.95356100e-12 3.49559812e-08 2.26298297e-07 1.78332982e-06\n",
            "  7.07669822e-16 2.67919172e-12 1.09068085e-21 9.99997973e-01\n",
            "  2.59043459e-12 6.82604737e-11]\n",
            " [3.63141362e-06 1.07943433e-05 9.99985576e-01 4.57149696e-08\n",
            "  3.53511664e-10 3.50122487e-09 1.45879913e-08 2.53635113e-10\n",
            "  1.02193569e-08 1.89648220e-14]\n",
            " [2.46600198e-08 9.99968648e-01 5.27822976e-07 1.17593650e-07\n",
            "  5.91612448e-09 2.70496257e-05 3.37414372e-06 2.38830978e-07\n",
            "  4.75926747e-08 1.49681316e-08]\n",
            " [9.99926805e-01 3.02223052e-10 1.12429257e-08 2.66556762e-14\n",
            "  9.58145854e-11 6.23238011e-05 1.08704535e-05 1.15117889e-11\n",
            "  6.21392138e-09 7.64433228e-09]\n",
            " [1.19750848e-13 4.59758360e-12 3.74009261e-15 7.24467348e-14\n",
            "  9.99999523e-01 3.71890756e-12 4.87596161e-12 2.44785203e-13\n",
            "  3.36561681e-11 5.15697991e-07]\n",
            " [6.72107592e-10 9.99999046e-01 5.09319591e-08 3.50835611e-10\n",
            "  1.72180847e-09 8.41109056e-07 4.29469686e-08 4.01689562e-08\n",
            "  1.15139487e-09 7.09101267e-09]\n",
            " [2.30166677e-15 1.90795461e-07 1.10184244e-10 1.92525537e-10\n",
            "  9.99992490e-01 6.49275023e-10 4.06058007e-14 1.52533403e-06\n",
            "  1.03392119e-06 4.69246243e-06]\n",
            " [3.28896697e-08 8.76557408e-07 6.32581321e-10 1.19448389e-08\n",
            "  1.65993624e-05 1.43647890e-06 6.81140420e-13 3.41780014e-06\n",
            "  2.41829730e-05 9.99953389e-01]\n",
            " [3.86743850e-05 5.34268452e-08 3.35854615e-08 7.52825918e-06\n",
            "  6.17179512e-06 9.77915049e-01 5.11310958e-08 1.94139496e-08\n",
            "  2.17107497e-02 3.21623840e-04]]\n",
            "[7 2 1 0 4 1 4 9 5]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}