{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1stDNN_Monimoy_Changes_1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/monimoyd/1stDNN/blob/master/1stDNN_Monimoy_Changes_1.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "_P38hI5pMQn7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0c908459-b605-4173-a74a-624baa8688d1"
      },
      "cell_type": "code",
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "FRE_pKeOMloJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Add\n",
        "from keras.layers import Convolution2D, MaxPooling2D,AveragePooling2D\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kDgrP_i6MuAv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X1xcE5w_M0D-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "6d155954-f57b-43ac-d7dc-1232d4ad1679"
      },
      "cell_type": "code",
      "source": [
        "print (X_train.shape)\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(X_train[0])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fcc9a5b87b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fcd10799f98>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "rnVBLQ0oM3tx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ME3NIhU7M-tt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CL4cTsEDNIVn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bbe303e5-9a36-48de-82c1-76201aad6b4d"
      },
      "cell_type": "code",
      "source": [
        "y_train[:10]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "r7Xc2UoLNPUz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2lT78J18NTcH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "c2696e52-0cc5-47b9-fe43-fd08f6195451"
      },
      "cell_type": "code",
      "source": [
        "Y_train[:10]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "1kCv2_NvNYmu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "4421c2b7-c35c-4816-b8ab-6e3cae6d6cf5"
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Activation\n",
        "from keras.layers import AveragePooling2D\n",
        "model = Sequential()\n",
        "\n",
        "\n",
        "model.add(Convolution2D(64, 3, 3, activation='relu', input_shape=(28,28,1)))\n",
        "model.add(Convolution2D(32, 1, activation='relu'))\n",
        "model.add(Convolution2D(32, 3, 3, activation='relu'))\n",
        "model.add(Convolution2D(16, 1, activation='relu'))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))\n",
        "model.add(Convolution2D(10, 1, activation='relu'))\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu'))\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu'))\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu'))\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu'))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Convolution2D(10, 1))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\")`\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\")`\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\")`\n",
            "  app.launch_new_instance()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "tq3yh3-yNeXO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 691
        },
        "outputId": "7d5cc9e6-9cc2-497e-86e2-a74e33d51af6"
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 64)        640       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 26, 26, 32)        2080      \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 24, 24, 32)        9248      \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 24, 24, 16)        528       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 10, 10, 16)        2320      \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 10, 10, 10)        170       \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 8, 8, 10)          910       \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 6, 6, 10)          910       \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 4, 4, 10)          910       \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 2, 2, 10)          910       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 1, 1, 10)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 1, 1, 10)          110       \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 18,736\n",
            "Trainable params: 18,736\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sfd5_mlNNlZ6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fJMBN1neNp1s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6467
        },
        "outputId": "2a3b9402-53ca-4c33-dd87-27645e696c21"
      },
      "cell_type": "code",
      "source": [
        "model.fit(X_train, Y_train, batch_size=2048, nb_epoch=175, verbose=1)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/models.py:981: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/175\n",
            "60000/60000 [==============================] - 9s 152us/step - loss: 2.1976 - acc: 0.1454\n",
            "Epoch 2/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 1.7956 - acc: 0.3255\n",
            "Epoch 3/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 1.2440 - acc: 0.5448\n",
            "Epoch 4/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.8105 - acc: 0.7490\n",
            "Epoch 5/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.5096 - acc: 0.8602\n",
            "Epoch 6/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.3528 - acc: 0.9024\n",
            "Epoch 7/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.2782 - acc: 0.9214\n",
            "Epoch 8/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.2386 - acc: 0.9321\n",
            "Epoch 9/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.2123 - acc: 0.9395\n",
            "Epoch 10/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.1944 - acc: 0.9432\n",
            "Epoch 11/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.1789 - acc: 0.9473\n",
            "Epoch 12/175\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.1646 - acc: 0.9517\n",
            "Epoch 13/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.1544 - acc: 0.9544\n",
            "Epoch 14/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.1476 - acc: 0.9567\n",
            "Epoch 15/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.1372 - acc: 0.9597\n",
            "Epoch 16/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.1335 - acc: 0.9610\n",
            "Epoch 17/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.1262 - acc: 0.9625\n",
            "Epoch 18/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.1207 - acc: 0.9641\n",
            "Epoch 19/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.1241 - acc: 0.9626\n",
            "Epoch 20/175\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.1111 - acc: 0.9671\n",
            "Epoch 21/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.1055 - acc: 0.9683\n",
            "Epoch 22/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0989 - acc: 0.9706\n",
            "Epoch 23/175\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.1019 - acc: 0.9702\n",
            "Epoch 24/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0987 - acc: 0.9703\n",
            "Epoch 25/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0941 - acc: 0.9722\n",
            "Epoch 26/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0928 - acc: 0.9719\n",
            "Epoch 27/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0871 - acc: 0.9741\n",
            "Epoch 28/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0842 - acc: 0.9753\n",
            "Epoch 29/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0811 - acc: 0.9758\n",
            "Epoch 30/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0797 - acc: 0.9763\n",
            "Epoch 31/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0778 - acc: 0.9772\n",
            "Epoch 32/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0775 - acc: 0.9770\n",
            "Epoch 33/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0762 - acc: 0.9775\n",
            "Epoch 34/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0734 - acc: 0.9786\n",
            "Epoch 35/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0716 - acc: 0.9789\n",
            "Epoch 36/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0702 - acc: 0.9792\n",
            "Epoch 37/175\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.0711 - acc: 0.9794\n",
            "Epoch 38/175\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.0673 - acc: 0.9804\n",
            "Epoch 39/175\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.0655 - acc: 0.9808\n",
            "Epoch 40/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0725 - acc: 0.9788\n",
            "Epoch 41/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0653 - acc: 0.9808\n",
            "Epoch 42/175\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.0624 - acc: 0.9815\n",
            "Epoch 43/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0646 - acc: 0.9808\n",
            "Epoch 44/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0621 - acc: 0.9813\n",
            "Epoch 45/175\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.0637 - acc: 0.9812\n",
            "Epoch 46/175\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.0624 - acc: 0.9813\n",
            "Epoch 47/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0627 - acc: 0.9814\n",
            "Epoch 48/175\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.0596 - acc: 0.9819\n",
            "Epoch 49/175\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.0595 - acc: 0.9824\n",
            "Epoch 50/175\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.0562 - acc: 0.9834\n",
            "Epoch 51/175\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.0544 - acc: 0.9838\n",
            "Epoch 52/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0544 - acc: 0.9841\n",
            "Epoch 53/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0549 - acc: 0.9838\n",
            "Epoch 54/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0536 - acc: 0.9840\n",
            "Epoch 55/175\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.0543 - acc: 0.9838\n",
            "Epoch 56/175\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.0530 - acc: 0.9841\n",
            "Epoch 57/175\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.0508 - acc: 0.9850\n",
            "Epoch 58/175\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.0512 - acc: 0.9848\n",
            "Epoch 59/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0526 - acc: 0.9845\n",
            "Epoch 60/175\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.0502 - acc: 0.9849\n",
            "Epoch 61/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0482 - acc: 0.9859\n",
            "Epoch 62/175\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.0482 - acc: 0.9863\n",
            "Epoch 63/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0481 - acc: 0.9857\n",
            "Epoch 64/175\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.0479 - acc: 0.9862\n",
            "Epoch 65/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0483 - acc: 0.9858\n",
            "Epoch 66/175\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.0513 - acc: 0.9846\n",
            "Epoch 67/175\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.0472 - acc: 0.9859\n",
            "Epoch 68/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0454 - acc: 0.9863\n",
            "Epoch 69/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0440 - acc: 0.9869\n",
            "Epoch 70/175\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.0427 - acc: 0.9872\n",
            "Epoch 71/175\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.0431 - acc: 0.9868\n",
            "Epoch 72/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0448 - acc: 0.9864\n",
            "Epoch 73/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0452 - acc: 0.9869\n",
            "Epoch 74/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0433 - acc: 0.9871\n",
            "Epoch 75/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0437 - acc: 0.9869\n",
            "Epoch 76/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0399 - acc: 0.9885\n",
            "Epoch 77/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0415 - acc: 0.9878\n",
            "Epoch 78/175\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.0386 - acc: 0.9889\n",
            "Epoch 79/175\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.0406 - acc: 0.9880\n",
            "Epoch 80/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0393 - acc: 0.9885\n",
            "Epoch 81/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0384 - acc: 0.9890\n",
            "Epoch 82/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0400 - acc: 0.9881\n",
            "Epoch 83/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0417 - acc: 0.9874\n",
            "Epoch 84/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0373 - acc: 0.9889\n",
            "Epoch 85/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0359 - acc: 0.9894\n",
            "Epoch 86/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0338 - acc: 0.9900\n",
            "Epoch 87/175\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.0370 - acc: 0.9888\n",
            "Epoch 88/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0356 - acc: 0.9896\n",
            "Epoch 89/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0353 - acc: 0.9894\n",
            "Epoch 90/175\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.0335 - acc: 0.9900\n",
            "Epoch 91/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0336 - acc: 0.9901\n",
            "Epoch 92/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0337 - acc: 0.9901\n",
            "Epoch 93/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0331 - acc: 0.9902\n",
            "Epoch 94/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0347 - acc: 0.9897\n",
            "Epoch 95/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0331 - acc: 0.9901\n",
            "Epoch 96/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0352 - acc: 0.9896\n",
            "Epoch 97/175\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.0352 - acc: 0.9894\n",
            "Epoch 98/175\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.0337 - acc: 0.9900\n",
            "Epoch 99/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0313 - acc: 0.9913\n",
            "Epoch 100/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0322 - acc: 0.9900\n",
            "Epoch 101/175\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.0316 - acc: 0.9905\n",
            "Epoch 102/175\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.0328 - acc: 0.9901\n",
            "Epoch 103/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0317 - acc: 0.9905\n",
            "Epoch 104/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0294 - acc: 0.9910\n",
            "Epoch 105/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0291 - acc: 0.9912\n",
            "Epoch 106/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0288 - acc: 0.9916\n",
            "Epoch 107/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0310 - acc: 0.9906\n",
            "Epoch 108/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0301 - acc: 0.9909\n",
            "Epoch 109/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0338 - acc: 0.9892\n",
            "Epoch 110/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0286 - acc: 0.9913\n",
            "Epoch 111/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0312 - acc: 0.9903\n",
            "Epoch 112/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0270 - acc: 0.9918\n",
            "Epoch 113/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0269 - acc: 0.9919\n",
            "Epoch 114/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0274 - acc: 0.9917\n",
            "Epoch 115/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0301 - acc: 0.9905\n",
            "Epoch 116/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0279 - acc: 0.9914\n",
            "Epoch 117/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0292 - acc: 0.9911\n",
            "Epoch 118/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0301 - acc: 0.9906\n",
            "Epoch 119/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0260 - acc: 0.9919\n",
            "Epoch 120/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0237 - acc: 0.9927\n",
            "Epoch 121/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0249 - acc: 0.9924\n",
            "Epoch 122/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0257 - acc: 0.9920\n",
            "Epoch 123/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0289 - acc: 0.9909\n",
            "Epoch 124/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0260 - acc: 0.9921\n",
            "Epoch 125/175\n",
            "60000/60000 [==============================] - 6s 94us/step - loss: 0.0247 - acc: 0.9925\n",
            "Epoch 126/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0257 - acc: 0.9920\n",
            "Epoch 127/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0244 - acc: 0.9924\n",
            "Epoch 128/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0236 - acc: 0.9929\n",
            "Epoch 129/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0247 - acc: 0.9925\n",
            "Epoch 130/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0252 - acc: 0.9918\n",
            "Epoch 131/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0283 - acc: 0.9910\n",
            "Epoch 132/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0285 - acc: 0.9910\n",
            "Epoch 133/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0235 - acc: 0.9927\n",
            "Epoch 134/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0223 - acc: 0.9932\n",
            "Epoch 135/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0228 - acc: 0.9932\n",
            "Epoch 136/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0228 - acc: 0.9928\n",
            "Epoch 137/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0216 - acc: 0.9934\n",
            "Epoch 138/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0211 - acc: 0.9939\n",
            "Epoch 139/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0227 - acc: 0.9930\n",
            "Epoch 140/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0233 - acc: 0.9921\n",
            "Epoch 141/175\n",
            "60000/60000 [==============================] - 6s 94us/step - loss: 0.0203 - acc: 0.9938\n",
            "Epoch 142/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0255 - acc: 0.9917\n",
            "Epoch 143/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0265 - acc: 0.9915\n",
            "Epoch 144/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0246 - acc: 0.9919\n",
            "Epoch 145/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0191 - acc: 0.9941\n",
            "Epoch 146/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0197 - acc: 0.9939\n",
            "Epoch 147/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0224 - acc: 0.9927\n",
            "Epoch 148/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0197 - acc: 0.9939\n",
            "Epoch 149/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0218 - acc: 0.9930\n",
            "Epoch 150/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0221 - acc: 0.9926\n",
            "Epoch 151/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0231 - acc: 0.9925\n",
            "Epoch 152/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0200 - acc: 0.9939\n",
            "Epoch 153/175\n",
            "60000/60000 [==============================] - 6s 94us/step - loss: 0.0252 - acc: 0.9919\n",
            "Epoch 154/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0193 - acc: 0.9936\n",
            "Epoch 155/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0183 - acc: 0.9943\n",
            "Epoch 156/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0187 - acc: 0.9941\n",
            "Epoch 157/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0180 - acc: 0.9944\n",
            "Epoch 158/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0183 - acc: 0.9943\n",
            "Epoch 159/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0197 - acc: 0.9933\n",
            "Epoch 160/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0177 - acc: 0.9943\n",
            "Epoch 161/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0173 - acc: 0.9944\n",
            "Epoch 162/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0201 - acc: 0.9936\n",
            "Epoch 163/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0161 - acc: 0.9948\n",
            "Epoch 164/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0156 - acc: 0.9953\n",
            "Epoch 165/175\n",
            "60000/60000 [==============================] - 6s 94us/step - loss: 0.0177 - acc: 0.9944\n",
            "Epoch 166/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0154 - acc: 0.9952\n",
            "Epoch 167/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0155 - acc: 0.9952\n",
            "Epoch 168/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0203 - acc: 0.9929\n",
            "Epoch 169/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0158 - acc: 0.9949\n",
            "Epoch 170/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0159 - acc: 0.9950\n",
            "Epoch 171/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0142 - acc: 0.9955\n",
            "Epoch 172/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0150 - acc: 0.9950\n",
            "Epoch 173/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0185 - acc: 0.9941\n",
            "Epoch 174/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0155 - acc: 0.9954\n",
            "Epoch 175/175\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0174 - acc: 0.9943\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fcd06b3ca90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "nvM-hwREP3Uk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UpW9QYCjQBEQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0e451a88-1b76-4840-817b-e9ce5a70c826"
      },
      "cell_type": "code",
      "source": [
        "print(score)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.03825586722440203, 0.9901]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZTo3owzcQIwE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f8pvBUe3QOE_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "ec62ccd9-b989-43a9-a6a5-03f8fcd5f2c5"
      },
      "cell_type": "code",
      "source": [
        "print(y_pred[:9])\n",
        "print(y_test[:9])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[5.5171503e-13 2.2555360e-09 6.9487022e-10 6.7390893e-10 1.3689918e-12\n",
            "  2.0255163e-07 7.9698479e-16 9.9999762e-01 1.1843820e-08 2.1066608e-06]\n",
            " [6.8859277e-05 2.6900489e-07 9.9993038e-01 5.8076304e-09 1.2583326e-10\n",
            "  7.5631504e-15 4.9261229e-07 1.3895866e-13 3.4094555e-10 8.3323641e-14]\n",
            " [4.8776986e-08 9.9992645e-01 9.1783763e-09 4.8031119e-08 2.6954391e-05\n",
            "  1.3375228e-07 8.3638076e-11 4.4570581e-05 1.5103016e-06 4.3376014e-07]\n",
            " [9.9998581e-01 9.2176928e-13 2.2741014e-09 1.3928275e-12 1.0473798e-09\n",
            "  3.2760022e-07 9.0822732e-06 6.8670819e-16 2.8917635e-10 4.7172753e-06]\n",
            " [8.1391404e-12 6.8833723e-12 7.9456103e-12 2.8342937e-16 9.9999952e-01\n",
            "  2.0314857e-13 8.1751932e-11 8.2959030e-12 1.4022727e-11 4.6344238e-07]\n",
            " [1.7934365e-08 9.9996066e-01 6.7856241e-09 2.3586198e-08 1.1524869e-05\n",
            "  2.7717165e-08 1.9499685e-11 2.7427441e-05 2.3173880e-07 1.4033770e-07]\n",
            " [4.7817578e-14 1.1949693e-13 3.8416438e-17 8.7133900e-20 9.9999988e-01\n",
            "  1.3216892e-13 9.1539254e-13 1.0552576e-12 3.9721565e-10 9.0673588e-08]\n",
            " [2.8754889e-07 2.6087959e-13 2.5254928e-07 7.1703967e-09 1.6106408e-03\n",
            "  1.8303399e-07 2.8179389e-11 2.2480467e-10 5.9428810e-05 9.9832922e-01]\n",
            " [3.8514085e-05 2.7679957e-18 1.2544255e-16 6.8196434e-18 2.1810838e-09\n",
            "  9.9303716e-01 4.7596889e-03 6.5663026e-09 5.1939520e-07 2.1641585e-03]]\n",
            "[7 2 1 0 4 1 4 9 5]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}